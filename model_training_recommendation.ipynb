{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (torch.cuda.is_available())\n",
    "print (torch.cuda.current_device())\n",
    "print (torch.cuda.get_device_name(0))\n",
    "print (torch.cuda.memory_allocated())\n",
    "print (torch.cuda.memory_cached())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleaned_steam_data_3-29.csv\", encoding='utf8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_columns = [x for x in df.columns.tolist() if x.startswith('title_')]\n",
    "drop_cols = ['funny', 'is_early_access_review', 'helpful', 'review', 'cleaned_reviews', 'hour_played', 'Year', 'Month', 'Day']\n",
    "drop_cols += title_columns\n",
    "\n",
    "df.drop(drop_cols, axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert to classification problem --> turn helpful to 0s 1s\n",
    "# new_helpful = []\n",
    "# num_positive = 0\n",
    "# for val in df.helpful.tolist():\n",
    "#     if val > 0:\n",
    "#         new_helpful.append(1)\n",
    "#         num_positive += 1\n",
    "#     else:\n",
    "#         new_helpful.append(0)\n",
    "# df.drop(['helpful'], axis=1, inplace=True)\n",
    "# df['helpful'] = new_helpful\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = len(df.columns.tolist())-1\n",
    "VOCAB_SIZE = 41248 # should ideally just transport this from prev\n",
    "EMBED_DIM = 128\n",
    "LSTM_DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking = True\n",
    "\n",
    "        self.bias = bias\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        \n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.kaiming_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        \n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        feature_dim = self.feature_dim \n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim), \n",
    "            self.weight\n",
    "        ).view(-1, step_dim)\n",
    "        \n",
    "        if self.bias:\n",
    "            eij = eij + self.b\n",
    "            \n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        \n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "\n",
    "        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n",
    "\n",
    "        weighted_input = x * torch.unsqueeze(a, -1)\n",
    "        return torch.sum(weighted_input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pytorch model\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "class Attention_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention_Net, self).__init__()\n",
    "        \n",
    "        # define architecture\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, EMBED_DIM)\n",
    "#         self.embedding_dropout = nn.Dropout2d(DROPOUT) # take this out potentially\n",
    "        \n",
    "        self.lstm = nn.LSTM(EMBED_DIM, LSTM_DIM, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # attention layer\n",
    "        self.attention_layer = Attention(LSTM_DIM * 2, MAX_SEQ_LEN)\n",
    "        \n",
    "        self.linear = nn.Linear(LSTM_DIM * 2, 2) # change here to 1 or 2 depending on loss\n",
    "        \n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "        #self.softmax = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0)).view(BATCH_SIZE, MAX_SEQ_LEN, -1)\n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        h_lstm_atten = self.attention_layer(h_lstm)\n",
    "        out = self.linear(h_lstm_atten)\n",
    "        softmax_out = self.softmax(out)\n",
    "        return softmax_out\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteamDataset(data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        #'Initialization'\n",
    "        self.data = data\n",
    "        text_cols = [x for x in df.columns.tolist() if x.startswith(\"encoded\")]\n",
    "        self.train = torch.tensor(data[text_cols].values).cuda()\n",
    "        labels = data['recommendation'].tolist()\n",
    "        \n",
    "        self.one_hot_labels = torch.tensor(np.array(labels)).squeeze().type(torch.LongTensor).cuda() # change to longtensor if using custom loss\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        #'Denotes the total number of samples'\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #'Generates one sample of data'\n",
    "        \n",
    "        # Load data and get label\n",
    "        X = self.train[index]\n",
    "        Y = self.one_hot_labels[index]\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = int(0.8 * len(df))\n",
    "steam_dataset = SteamDataset(df[:train_num])\n",
    "steam_data_loader = data.DataLoader(steam_dataset, batch_size=BATCH_SIZE, num_workers=0, drop_last=True)\n",
    "steam_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_negative = len(df) - num_positive\n",
    "# print ('positive examples = ', num_positive)\n",
    "# print ('negative examples = ', num_negative)\n",
    "\n",
    "# weights = torch.tensor([1/(num_negative / len(df)), 1 / (num_positive / len(df))]).cuda()\n",
    "# weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_model = Attention_Net().cuda()\n",
    "# loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(attention_model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def weighted_binary_cross_entropy(output, target, weights=None):\n",
    "        \n",
    "#     if weights is not None:\n",
    "#         assert len(weights) == 2\n",
    "        \n",
    "#         loss = weights[1] * (target * torch.log(output)) + \\\n",
    "#                weights[0] * ((1 - target) * torch.log(1 - output))\n",
    "#     else:\n",
    "#         loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
    "\n",
    "#     return torch.neg(torch.mean(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "EPOCHS = 100\n",
    "start = time.time()\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    second_start = time.time()\n",
    "    running_loss = 0\n",
    "\n",
    "    with tqdm(total=len(steam_data_loader), file=sys.stdout) as pbar:\n",
    "        for idx, (train_X, train_Y) in enumerate(steam_data_loader):\n",
    "            attention_model.zero_grad()\n",
    "            pred_y = attention_model(train_X)       \n",
    "\n",
    "            # loss = weighted_binary_cross_entropy(pred_y, train_Y, weights)\n",
    "\n",
    "            loss = loss_function(pred_y, train_Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss\n",
    "            pbar.set_description('Epoch {} | summed loss = {}'.format(i+1, torch.round(running_loss)))\n",
    "            pbar.update(1)\n",
    "            tqdm._instances.clear()\n",
    "    \n",
    "\n",
    "    print ('Epoch {} | took {} seconds | summed loss: {} | avg loss: {}'\n",
    "                   .format(i+1, time.time() - second_start, running_loss, running_loss / len(steam_dataset)))\n",
    "\n",
    "print (\"Took {} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_eval_dataset = SteamDataset(df[train_num:])\n",
    "steam_eval_data_loader = data.DataLoader(steam_eval_dataset, batch_size=16, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "correct = 0\n",
    "eval_loss = 0\n",
    "with torch.no_grad():\n",
    "    for i, (test_X, test_Y) in enumerate(steam_eval_data_loader):\n",
    "        preds = attention_model(test_X)\n",
    "        for idx, each_pred in enumerate(preds):\n",
    "            if each_pred[0] >= 0.5 and test_Y[idx] == 0:\n",
    "                correct += 1\n",
    "            elif each_pred[0] < 0.5 and test_Y[idx] == 1:\n",
    "                correct += 1\n",
    "        loss = loss_function(preds, test_Y)\n",
    "        eval_loss += loss\n",
    "        \n",
    "        \n",
    "print (\"Eval accuracy: {}\".format(correct / len(steam_eval_dataset)))\n",
    "print (\"Eval summed loss: {} | avg loss: {}\".format(eval_loss, eval_loss / len(steam_eval_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'models/word200_date3-31_epoch20.pt'\n",
    "torch.save(attention_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
