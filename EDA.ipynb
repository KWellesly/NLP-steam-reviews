{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/steam_reviews.csv\"\n",
    "df = pd.read_csv(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recommendation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "131298 / (131298 +303593)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seems like majority of reviews are for recommendations, interesting\n",
    "df['recommendation'].value_counts().plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most games are not early access\n",
    "df['is_early_access_review'].value_counts().plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exponential dropoff, most reviews are for PUBG\n",
    "df['title'].value_counts()[:10].plot(kind=\"bar\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 48 unique games... hmm\n",
    "len(df['title'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as expected, most reviews dont get voted for being funny\n",
    "df['funny'].value_counts()[:20].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as expected, most reviews dont get voted for being helpful\n",
    "df['helpful'].value_counts()[:20].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df.helpful.tolist(), bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 91% of the data is 0 helpful\n",
    "np.percentile(df.helpful.tolist(), 97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(df.helpful.tolist(), 91.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# see what funny + helpful does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "funny = df.funny.tolist()\n",
    "helpful = df.helpful.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "useful = []\n",
    "for i in range(len(funny)):\n",
    "    useful.append(funny[i] + helpful[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.percentile(useful, 91)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "steam_rev = df.review.tolist()\n",
    "steam_precleaned = {}\n",
    "\n",
    "for i, review in enumerate(steam_rev):\n",
    "    each_cleaned_review = []\n",
    "    words = review.split(\" \")\n",
    "    for idx, each_word in enumerate(words):\n",
    "        if each_word not in steam_precleaned.keys():\n",
    "            steam_precleaned[each_word] = 1\n",
    "        else:\n",
    "            steam_precleaned[each_word] = steam_precleaned[each_word] + 1\n",
    "\n",
    "steam_pre_words = OrderedDict(sorted(steam_precleaned.items(), key = itemgetter(1), reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(steam_pre_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_pre_words = OrderedDict(sorted(steam_precleaned.items(), key = itemgetter(1), reverse = True)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(steam_pre_words)), list(steam_pre_words.values()), align='center')\n",
    "plt.xticks(range(len(steam_pre_words)), list(steam_pre_words.keys()), rotation=90)\n",
    "plt.title('Pre-Cleaned Steam Dataset 50 Most Frequent Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = af.loc[af['recommendation'] == 1].cleaned_reviews\n",
    "norec = af.loc[af['recommendation'] == 0].cleaned_reviews\n",
    "\n",
    "steam_rec = {}\n",
    "steam_norec = {}\n",
    "\n",
    "for i, review in enumerate(rec):\n",
    "    each_cleaned_review = []\n",
    "    words = review.split(\" \")\n",
    "    for idx, each_word in enumerate(words):\n",
    "        if each_word not in steam_rec.keys():\n",
    "            steam_rec[each_word] = 1\n",
    "        else:\n",
    "            steam_rec[each_word] = steam_rec[each_word] + 1\n",
    "\n",
    "steam_rec = OrderedDict(sorted(steam_rec.items(), key = itemgetter(1), reverse = True))\n",
    "\n",
    "for i, review in enumerate(norec):\n",
    "    each_cleaned_review = []\n",
    "    words = review.split(\" \")\n",
    "    for idx, each_word in enumerate(words):\n",
    "        if each_word not in steam_norec.keys():\n",
    "            steam_norec[each_word] = 1\n",
    "        else:\n",
    "            steam_norec[each_word] = steam_norec[each_word] + 1\n",
    "\n",
    "steam_norec = OrderedDict(sorted(steam_norec.items(), key = itemgetter(1), reverse = True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_norec = OrderedDict(sorted(steam_norec.items(), key = itemgetter(1), reverse = True)[:50])\n",
    "print(steam_norec)\n",
    "plt.bar(range(len(steam_norec)), list(steam_norec.values()), align='center')\n",
    "plt.xticks(range(len(steam_norec)), list(steam_norec.keys()), rotation=90)\n",
    "plt.title('Not Recommended Steam Reviews 50 Most Frequent Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_rec = OrderedDict(sorted(steam_rec.items(), key = itemgetter(1), reverse = True)[:50])\n",
    "print(steam_rec)\n",
    "plt.bar(range(len(steam_rec)), list(steam_rec.values()), align='center')\n",
    "plt.xticks(range(len(steam_rec)), list(steam_rec.keys()), rotation=90)\n",
    "plt.title('Recommended Steam Reviews 50 Most Frequent Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = pd.read_csv(\"data/cleaned_steam_data_4-15_15Kwords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "af.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_steam_rev = af.cleaned_reviews.tolist()\n",
    "steam_postcleaned = {}\n",
    "\n",
    "for i, review in enumerate(cleaned_steam_rev):\n",
    "    each_cleaned_review = []\n",
    "    words = review.split(\" \")\n",
    "    for idx, each_word in enumerate(words):\n",
    "        if each_word not in steam_postcleaned.keys():\n",
    "            steam_postcleaned[each_word] = 1\n",
    "        else:\n",
    "            steam_postcleaned[each_word] = steam_postcleaned[each_word] + 1\n",
    "\n",
    "steam_post_words = OrderedDict(sorted(steam_postcleaned.items(), key = itemgetter(1), reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(steam_post_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_post_words = OrderedDict(sorted(steam_postcleaned.items(), key = itemgetter(1), reverse = True)[:50])\n",
    "plt.bar(range(len(steam_post_words)), list(steam_post_words.values()), align='center')\n",
    "plt.xticks(range(len(steam_post_words)), list(steam_post_words.keys()), rotation=90)\n",
    "plt.title('Post-Cleaned Steam Dataset 50 Most Frequent Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "\n",
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df_a = getDF('data/reviews_Video_Games_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ama_rev = df_a.reviewText.tolist()\n",
    "ama_precleaned = {}\n",
    "\n",
    "for i, review in enumerate(ama_rev):\n",
    "    each_cleaned_review = []\n",
    "    words = review.split(\" \")\n",
    "    for idx, each_word in enumerate(words):\n",
    "        if each_word not in ama_precleaned.keys():\n",
    "            ama_precleaned[each_word] = 1\n",
    "        else:\n",
    "            ama_precleaned[each_word] = ama_precleaned[each_word] + 1\n",
    "\n",
    "ama_precleaned = OrderedDict(sorted(ama_precleaned.items(), key = itemgetter(1), reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ama_precleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ama_precleaned = OrderedDict(sorted(ama_precleaned.items(), key = itemgetter(1), reverse = True)[:50])\n",
    "plt.bar(range(len(ama_precleaned)), list(ama_precleaned.values()), align='center')\n",
    "plt.xticks(range(len(ama_precleaned)), list(ama_precleaned.keys()), rotation=90)\n",
    "plt.title('Pre-Cleaned Amazon Dataset 50 Most Frequent Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ac = pd.read_csv(\"data/cleaned_amzn_data_4-15_10Kwords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_ama_rev = df_ac.cleaned_reviews.tolist()\n",
    "ama_postcleaned = {}\n",
    "\n",
    "for i, review in enumerate(cleaned_ama_rev):\n",
    "    each_cleaned_review = []\n",
    "    words = review.split(\" \")\n",
    "    for idx, each_word in enumerate(words):\n",
    "        if each_word not in ama_postcleaned.keys():\n",
    "            ama_postcleaned[each_word] = 1\n",
    "        else:\n",
    "            ama_postcleaned[each_word] = ama_postcleaned[each_word] + 1\n",
    "\n",
    "ama_postcleaned = OrderedDict(sorted(ama_postcleaned.items(), key = itemgetter(1), reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ama_postcleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ama_postcleaned = OrderedDict(sorted(ama_postcleaned.items(), key = itemgetter(1), reverse = True)[:50])\n",
    "plt.bar(range(len(ama_postcleaned)), list(ama_postcleaned.values()), align='center')\n",
    "plt.xticks(range(len(ama_postcleaned)), list(ama_postcleaned.keys()), rotation=90)\n",
    "plt.title('Post-Cleaned Amazon Dataset 50 Most Frequent Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ac.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "arec = df_ac.loc[df_ac['overall'] == 1].cleaned_reviews\n",
    "anorec = df_ac.loc[df_ac['overall'] == 0].cleaned_reviews\n",
    "\n",
    "a_rec = {}\n",
    "a_norec = {}\n",
    "\n",
    "for i, review in enumerate(arec):\n",
    "    each_cleaned_review = []\n",
    "    words = review.split(\" \")\n",
    "    for idx, each_word in enumerate(words):\n",
    "        if each_word not in a_rec.keys():\n",
    "            a_rec[each_word] = 1\n",
    "        else:\n",
    "            a_rec[each_word] = a_rec[each_word] + 1\n",
    "\n",
    "a_rec = OrderedDict(sorted(a_rec.items(), key = itemgetter(1), reverse = True))\n",
    "\n",
    "for i, review in enumerate(anorec):\n",
    "    each_cleaned_review = []\n",
    "    words = review.split(\" \")\n",
    "    for idx, each_word in enumerate(words):\n",
    "        if each_word not in a_norec.keys():\n",
    "            a_norec[each_word] = 1\n",
    "        else:\n",
    "            a_norec[each_word] = a_norec[each_word] + 1\n",
    "\n",
    "a_norec = OrderedDict(sorted(a_norec.items(), key = itemgetter(1), reverse = True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "a_rec = OrderedDict(sorted(a_rec.items(), key = itemgetter(1), reverse = True)[:50])\n",
    "print(a_rec)\n",
    "plt.bar(range(len(a_rec)), list(a_rec.values()), align='center')\n",
    "plt.xticks(range(len(a_rec)), list(a_rec.keys()), rotation=90)\n",
    "plt.title('Recommended Amazon Reviews 50 Most Frequent Words')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "a_norec = OrderedDict(sorted(a_norec.items(), key = itemgetter(1), reverse = True)[:50])\n",
    "print(a_norec)\n",
    "plt.bar(range(len(a_norec)), list(a_norec.values()), align='center')\n",
    "plt.xticks(range(len(a_norec)), list(a_norec.keys()), rotation=90)\n",
    "plt.title('Not Recommended Amazon Reviews 50 Most Frequent Words')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning curve graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "baseline1 = np.load('data/baseline_y_axis.npy') # batch 64\n",
    "baseline2 = np.load('data/baseline2_y_axis.npy') # batch 64\n",
    "baseline3 = np.load('data/baseline3_y_axis.npy') # batch 64\n",
    "baseline4 = np.load('data/baseline4_y_axis.npy') # batch 64\n",
    "prod = np.load('data/transferlearning_y_axis.npy') # batch 64\n",
    "\n",
    "baseline_x = range(1, 51)\n",
    "prod_x = range(1, 21)\n",
    "plt.plot(baseline_x, baseline1, 'r--', label='Baseline 1')\n",
    "plt.plot(baseline_x, baseline2*2, 'b--', label='Baseline 2')\n",
    "plt.plot(baseline_x, baseline3, '--', label='Baseline 3')\n",
    "plt.plot(baseline_x, baseline4, 'y--', label='Baseline 4')\n",
    "plt.plot(prod_x, prod, label='Transfer learning')\n",
    "plt.title(\"Learning Curve for Baseline and Transfer Learning Models\", size=20)\n",
    "plt.xlabel(\"Epochs\", size=15)\n",
    "plt.ylabel(\"Summed Loss\", size=15)\n",
    "plt.legend( prop={'size': 15})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
