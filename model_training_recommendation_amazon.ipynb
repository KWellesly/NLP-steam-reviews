{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "\n",
    "# gensim for pretrained embedding\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import datapath, get_tmpfile\n",
    "\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# torchtext\n",
    "import torchtext.vocab as vocab\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "GeForce GTX 1060 with Max-Q Design\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print (torch.cuda.is_available())\n",
    "print (torch.cuda.current_device())\n",
    "print (torch.cuda.get_device_name(0))\n",
    "print (torch.cuda.memory_allocated())\n",
    "print (torch.cuda.memory_cached())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleaned_amzn_data_4-15_10Kwords.csv\", encoding='utf8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendation</th>\n",
       "      <th>encoded_1</th>\n",
       "      <th>encoded_2</th>\n",
       "      <th>encoded_3</th>\n",
       "      <th>encoded_4</th>\n",
       "      <th>encoded_5</th>\n",
       "      <th>encoded_6</th>\n",
       "      <th>encoded_7</th>\n",
       "      <th>encoded_8</th>\n",
       "      <th>encoded_9</th>\n",
       "      <th>...</th>\n",
       "      <th>encoded_185</th>\n",
       "      <th>encoded_186</th>\n",
       "      <th>encoded_187</th>\n",
       "      <th>encoded_188</th>\n",
       "      <th>encoded_189</th>\n",
       "      <th>encoded_190</th>\n",
       "      <th>encoded_191</th>\n",
       "      <th>encoded_192</th>\n",
       "      <th>encoded_193</th>\n",
       "      <th>encoded_194</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4059</td>\n",
       "      <td>9289</td>\n",
       "      <td>8594</td>\n",
       "      <td>9289</td>\n",
       "      <td>4934</td>\n",
       "      <td>7474</td>\n",
       "      <td>3382</td>\n",
       "      <td>652</td>\n",
       "      <td>2097</td>\n",
       "      <td>2876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3340</td>\n",
       "      <td>8561</td>\n",
       "      <td>9289</td>\n",
       "      <td>214</td>\n",
       "      <td>5126</td>\n",
       "      <td>6257</td>\n",
       "      <td>2827</td>\n",
       "      <td>6823</td>\n",
       "      <td>1256</td>\n",
       "      <td>8798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1745</td>\n",
       "      <td>5242</td>\n",
       "      <td>506</td>\n",
       "      <td>2434</td>\n",
       "      <td>7599</td>\n",
       "      <td>8764</td>\n",
       "      <td>5242</td>\n",
       "      <td>7146</td>\n",
       "      <td>6949</td>\n",
       "      <td>3506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7514</td>\n",
       "      <td>5853</td>\n",
       "      <td>5815</td>\n",
       "      <td>9606</td>\n",
       "      <td>595</td>\n",
       "      <td>8561</td>\n",
       "      <td>243</td>\n",
       "      <td>2076</td>\n",
       "      <td>2734</td>\n",
       "      <td>9289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8375</td>\n",
       "      <td>3595</td>\n",
       "      <td>1356</td>\n",
       "      <td>2298</td>\n",
       "      <td>8561</td>\n",
       "      <td>7502</td>\n",
       "      <td>2298</td>\n",
       "      <td>1329</td>\n",
       "      <td>6555</td>\n",
       "      <td>6758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommendation  encoded_1  encoded_2  encoded_3  encoded_4  encoded_5  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               1          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "4               1          0          0          0          0          0   \n",
       "5               1          0          0          0          0          0   \n",
       "\n",
       "   encoded_6  encoded_7  encoded_8  encoded_9  ...  encoded_185  encoded_186  \\\n",
       "0          0          0          0          0  ...         4059         9289   \n",
       "1          0          0          0          0  ...         3340         8561   \n",
       "2          0          0          0          0  ...         1745         5242   \n",
       "4          0          0          0          0  ...         7514         5853   \n",
       "5          0          0          0          0  ...         8375         3595   \n",
       "\n",
       "   encoded_187  encoded_188  encoded_189  encoded_190  encoded_191  \\\n",
       "0         8594         9289         4934         7474         3382   \n",
       "1         9289          214         5126         6257         2827   \n",
       "2          506         2434         7599         8764         5242   \n",
       "4         5815         9606          595         8561          243   \n",
       "5         1356         2298         8561         7502         2298   \n",
       "\n",
       "   encoded_192  encoded_193  encoded_194  \n",
       "0          652         2097         2876  \n",
       "1         6823         1256         8798  \n",
       "2         7146         6949         3506  \n",
       "4         2076         2734         9289  \n",
       "5         1329         6555         6758  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = ['review', 'cleaned_reviews']\n",
    "\n",
    "try:\n",
    "    df.drop(drop_cols, axis=1, inplace=True)\n",
    "except:\n",
    "    print (\"Probably dropped already\")\n",
    "df = df.rename(columns={'overall': 'recommendation'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# google word2vec embedding #\n",
    "# embed_path = 'data/GoogleNews-vectors-negative300.bin.gz'\n",
    "# word2vec = KeyedVectors.load_word2vec_format(embed_path, binary=True)\n",
    "# weights = word2vec.wv.vectors\n",
    "# weights\n",
    "\n",
    "\n",
    "# glove embedding #\n",
    "glove_input_file = 'data/glove.6b/glove.6B.100d.txt'\n",
    "word2vec_output_file = 'data/glove_to_word2vec.txt'\n",
    "\n",
    "try:\n",
    "    pretrained_embedding = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "except:\n",
    "    print (\"Converting word2vec file. If this fails, please download the glove.6b.100d file\")\n",
    "    glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\kevin\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = pretrained_embedding.wv.vectors\n",
    "pretrained_embedding.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = len(df.columns.tolist())-1\n",
    "VOCAB_SIZE = 14845 # 10746 - but need to use max(amzn_vocab, steam_vocab)\n",
    "EMBED_DIM = 100\n",
    "LSTM_DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only need 2-3 lines for attention\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking = True\n",
    "\n",
    "        self.bias = bias\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        \n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.kaiming_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        \n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        feature_dim = self.feature_dim \n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim), \n",
    "            self.weight\n",
    "        ).view(-1, step_dim)\n",
    "        \n",
    "        if self.bias:\n",
    "            eij = eij + self.b\n",
    "            \n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        \n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "\n",
    "        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n",
    "\n",
    "        weighted_input = x * torch.unsqueeze(a, -1)\n",
    "        return torch.sum(weighted_input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pytorch model\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "class Attention_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention_Net, self).__init__()\n",
    "        \n",
    "        # define architecture\n",
    "        # self.embedding = nn.Embedding(VOCAB_SIZE, EMBED_DIM) # add pretrained embeding\n",
    "        weights_ = Variable(torch.from_numpy(weights))\n",
    "        print (weights_.size())\n",
    "        self.embedding = nn.Embedding.from_pretrained(weights_)\n",
    "    \n",
    "        self.lstm = nn.LSTM(EMBED_DIM, \n",
    "                            LSTM_DIM, \n",
    "                            bidirectional=True,\n",
    "                            dropout=0.2,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        # attention layer\n",
    "#         self.attention_layer = Attention(LSTM_DIM * 2, MAX_SEQ_LEN)\n",
    "        # try tanh\n",
    "\n",
    "        self.linear = nn.Linear(LSTM_DIM*2, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedding = self.embedding(x)\n",
    "        embedding = torch.squeeze(torch.unsqueeze(embedding, 0)).view(BATCH_SIZE, MAX_SEQ_LEN, -1)\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedding)\n",
    "#         attention = self.attention_layer(lstm_out)\n",
    "        \n",
    "        out = self.linear(lstm_out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmznDataset(data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        #'Initialization'\n",
    "        self.data = data\n",
    "        text_cols = [x for x in df.columns.tolist() if x.startswith(\"encoded\")]\n",
    "        self.train = torch.tensor(data[text_cols].values).type(torch.LongTensor).cuda()\n",
    "        labels = data['recommendation'].tolist()\n",
    "        \n",
    "        self.one_hot_labels = torch.tensor(np.array(labels)).squeeze().type(torch.LongTensor).cuda() # change to longtensor if using custom loss\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        #'Denotes the total number of samples'\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #'Generates one sample of data'\n",
    "        \n",
    "        # Load data and get label\n",
    "        X = self.train[index]\n",
    "        Y = self.one_hot_labels[index]\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2568283cd88>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num = int(0.8 * len(df))\n",
    "amzn_dataset = AmznDataset(df[:train_num])\n",
    "amzn_data_loader = data.DataLoader(amzn_dataset, batch_size=BATCH_SIZE, num_workers=0, drop_last=True, shuffle=True)\n",
    "amzn_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400000, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "attention_model = Attention_Net().cuda()\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(attention_model.parameters(), lr=0.0001) # even lower for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e4021f87dd44cb80943d53227b62a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1211.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 | took 28.01642632484436 seconds | summed loss: 657.1602172851562 | avg loss: 0.004239524714648724\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eafdbeeb2fc34799ad03a9e0a6e0ab86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1211.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 | took 27.78093409538269 seconds | summed loss: 606.8274536132812 | avg loss: 0.003914813976734877\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22366e67de9b4826826c433c5ad19d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1211.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 | took 27.57372522354126 seconds | summed loss: 576.8763427734375 | avg loss: 0.0037215908523648977\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed90bb36f2704890a95b56882662a4b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1211.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 | took 28.220147609710693 seconds | summed loss: 551.7191772460938 | avg loss: 0.003559294855222106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7032f22655bd46f2bddd90ec936387ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1211.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 | took 28.911523818969727 seconds | summed loss: 531.7894897460938 | avg loss: 0.0034307229798287153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d061874d9224ba9ab943c0c4cc80721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1211.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 | took 29.00606060028076 seconds | summed loss: 516.321044921875 | avg loss: 0.003330931765958667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ffcf2f486f44e887ba197c74b6589c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1211.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 | took 29.039900302886963 seconds | summed loss: 503.4665222167969 | avg loss: 0.0032480035442858934\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb72e11ce45c4c9fa55ae0e1c7935681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1211.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 | took 29.103739023208618 seconds | summed loss: 492.67901611328125 | avg loss: 0.003178410232067108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b795cf1e62774846aef69987d4fabb82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1211.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 | took 29.23008894920349 seconds | summed loss: 484.40185546875 | avg loss: 0.0031250121537595987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2cf78d87a74d5a9c064469d39fa545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1211.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 | took 29.237423181533813 seconds | summed loss: 476.58685302734375 | avg loss: 0.0030745952390134335\n",
      "Took 286.12692427635193 seconds\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "EPOCHS = 10\n",
    "start = time.time()\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    second_start = time.time()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    attention_model.train()\n",
    "    \n",
    "    with tqdm(total=len(amzn_data_loader), file=sys.stdout) as pbar:\n",
    "        for idx, (train_X, train_Y) in enumerate(amzn_data_loader):\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_y = attention_model(train_X) \n",
    "            loss = loss_function(pred_y, train_Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss\n",
    "\n",
    "            # calc accuracy\n",
    "            pred1_mask = pred_y[:, 1] > 0.5\n",
    "            masked_trainY_1 = train_Y[pred1_mask]\n",
    "            masked_trainY_0 = train_Y[~pred1_mask]\n",
    "            ones_predicted_correct = torch.sum(masked_trainY_1)\n",
    "            zeros_predicted_correct = torch.sum(masked_trainY_0)\n",
    "            correct += ones_predicted_correct.add(zeros_predicted_correct)\n",
    "            correct_ = correct.cpu().numpy()\n",
    "            \n",
    "            # update progress bar\n",
    "            pbar.set_description('ep{} | loss: {} | acc: {}%'.format(i+1, torch.round(running_loss), round(correct_ / ((idx+1) * BATCH_SIZE)*100, 1)))\n",
    "            pbar.update(1)\n",
    "            tqdm._instances.clear()\n",
    "            \n",
    "            \n",
    "\n",
    "    print ('Epoch {} | took {} seconds | summed loss: {} | avg loss: {}'\n",
    "                   .format(i+1, time.time() - second_start, running_loss, running_loss / (len(amzn_data_loader) * BATCH_SIZE)))\n",
    "\n",
    "print (\"Took {} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention_Net(\n",
      "  (embedding): Embedding(400000, 100)\n",
      "  (lstm): LSTM(100, 64, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (linear): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print (attention_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_eval_dataset = AmznDataset(df[train_num:])\n",
    "amzn_eval_data_loader = data.DataLoader(amzn_eval_dataset, batch_size=BATCH_SIZE, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.833922535029546\n",
      "Eval summed loss: 148.5374755859375 | avg loss: 0.003832928603515029\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "correct = 0\n",
    "eval_loss = 0\n",
    "attention_model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (test_X, test_Y) in enumerate(amzn_eval_data_loader):\n",
    "        preds = attention_model(test_X).squeeze()\n",
    "        preds = torch.nn.functional.softmax(preds)\n",
    "        for idx, each_pred in enumerate(preds):\n",
    "            if each_pred[0] >= 0.5 and test_Y[idx] == 0:\n",
    "                correct += 1\n",
    "            elif each_pred[0] < 0.5 and test_Y[idx] == 1:\n",
    "                correct += 1\n",
    "        loss = loss_function(preds, test_Y)\n",
    "        eval_loss += loss\n",
    "        \n",
    "        \n",
    "print (\"Eval accuracy: {}\".format(correct / len(amzn_eval_dataset)))\n",
    "print (\"Eval summed loss: {} | avg loss: {}\".format(eval_loss, eval_loss / len(amzn_eval_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'models/amzn_date4-16_batch128_epoch10_acc83_lstm64_pretrainedembedding_noattention.pt'\n",
    "torch.save(attention_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7620507421399227"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df.recommendation.tolist()) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 77.8% eval acc -- batch=128, lr=0.0001\n",
    "# 77.8% eval acc -- batch=128, lr=0.001\n",
    "# 77.9% eval acc -- batch=64, lr=0.001, embed_dim=16, lstm_dim=16\n",
    "# 85.9% eval acc -- batch=128, lr=0.0001, embed=128, lstm_dim=64\n",
    "# 86.1% eval acc -- batch=128, lr=0.0001, embed=128, lstm_dim=64, + attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scratchpaper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.5980,  0.9168,  0.8958], requires_grad=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(3, requires_grad=True)\n",
    "target = torch.empty(3).random_(2)\n",
    "\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
