{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleaned_steam_data_3-29.csv\", encoding='utf8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>funny</th>\n",
       "      <th>helpful</th>\n",
       "      <th>hour_played</th>\n",
       "      <th>is_early_access_review</th>\n",
       "      <th>recommendation</th>\n",
       "      <th>review</th>\n",
       "      <th>title_ACE COMBAT™ 7: SKIES UNKNOWN</th>\n",
       "      <th>title_ARK: Survival Evolved</th>\n",
       "      <th>title_ASTRONEER</th>\n",
       "      <th>title_Battlefleet Gothic: Armada 2</th>\n",
       "      <th>...</th>\n",
       "      <th>encoded_185</th>\n",
       "      <th>encoded_186</th>\n",
       "      <th>encoded_187</th>\n",
       "      <th>encoded_188</th>\n",
       "      <th>encoded_189</th>\n",
       "      <th>encoded_190</th>\n",
       "      <th>encoded_191</th>\n",
       "      <th>encoded_192</th>\n",
       "      <th>encoded_193</th>\n",
       "      <th>encoded_194</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>578</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>&amp;gt Played as German Reich&amp;gt Declare war on B...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33572</td>\n",
       "      <td>15335</td>\n",
       "      <td>18484</td>\n",
       "      <td>25557</td>\n",
       "      <td>18484</td>\n",
       "      <td>12429</td>\n",
       "      <td>8541</td>\n",
       "      <td>25557</td>\n",
       "      <td>14122</td>\n",
       "      <td>23610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>yes.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Very good game although a bit overpriced in my...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14122</td>\n",
       "      <td>39490</td>\n",
       "      <td>27271</td>\n",
       "      <td>39764</td>\n",
       "      <td>28167</td>\n",
       "      <td>8875</td>\n",
       "      <td>1494</td>\n",
       "      <td>40182</td>\n",
       "      <td>6951</td>\n",
       "      <td>39745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>295</td>\n",
       "      <td>219</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I have never been told to kill myself more tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34155</td>\n",
       "      <td>14517</td>\n",
       "      <td>19363</td>\n",
       "      <td>40032</td>\n",
       "      <td>14122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>380</td>\n",
       "      <td>271</td>\n",
       "      <td>414</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>if you think cs go is toxic try this game</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10818</td>\n",
       "      <td>2776</td>\n",
       "      <td>9421</td>\n",
       "      <td>19118</td>\n",
       "      <td>3218</td>\n",
       "      <td>14122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   funny  helpful  hour_played  is_early_access_review  recommendation  \\\n",
       "0      2        4          578                       0               1   \n",
       "1      0        0          184                       0               1   \n",
       "2      0        0          892                       0               1   \n",
       "7    295      219           71                       0               1   \n",
       "9    380      271          414                       0               1   \n",
       "\n",
       "                                              review  \\\n",
       "0  &gt Played as German Reich&gt Declare war on B...   \n",
       "1                                               yes.   \n",
       "2  Very good game although a bit overpriced in my...   \n",
       "7  I have never been told to kill myself more tha...   \n",
       "9          if you think cs go is toxic try this game   \n",
       "\n",
       "   title_ACE COMBAT™ 7: SKIES UNKNOWN  title_ARK: Survival Evolved  \\\n",
       "0                                   0                            0   \n",
       "1                                   0                            0   \n",
       "2                                   0                            0   \n",
       "7                                   0                            0   \n",
       "9                                   0                            0   \n",
       "\n",
       "   title_ASTRONEER  title_Battlefleet Gothic: Armada 2  ...  encoded_185  \\\n",
       "0                0                                   0  ...        33572   \n",
       "1                0                                   0  ...            0   \n",
       "2                0                                   0  ...        14122   \n",
       "7                0                                   0  ...            0   \n",
       "9                0                                   0  ...            0   \n",
       "\n",
       "   encoded_186  encoded_187  encoded_188  encoded_189  encoded_190  \\\n",
       "0        15335        18484        25557        18484        12429   \n",
       "1            0            0            0            0            0   \n",
       "2        39490        27271        39764        28167         8875   \n",
       "7            0            0            0            0        34155   \n",
       "9            0            0            0        10818         2776   \n",
       "\n",
       "   encoded_191  encoded_192  encoded_193  encoded_194  \n",
       "0         8541        25557        14122        23610  \n",
       "1            0            0            0        30552  \n",
       "2         1494        40182         6951        39745  \n",
       "7        14517        19363        40032        14122  \n",
       "9         9421        19118         3218        14122  \n",
       "\n",
       "[5 rows x 252 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>helpful</th>\n",
       "      <th>encoded_1</th>\n",
       "      <th>encoded_2</th>\n",
       "      <th>encoded_3</th>\n",
       "      <th>encoded_4</th>\n",
       "      <th>encoded_5</th>\n",
       "      <th>encoded_6</th>\n",
       "      <th>encoded_7</th>\n",
       "      <th>encoded_8</th>\n",
       "      <th>encoded_9</th>\n",
       "      <th>...</th>\n",
       "      <th>encoded_185</th>\n",
       "      <th>encoded_186</th>\n",
       "      <th>encoded_187</th>\n",
       "      <th>encoded_188</th>\n",
       "      <th>encoded_189</th>\n",
       "      <th>encoded_190</th>\n",
       "      <th>encoded_191</th>\n",
       "      <th>encoded_192</th>\n",
       "      <th>encoded_193</th>\n",
       "      <th>encoded_194</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>33572</td>\n",
       "      <td>15335</td>\n",
       "      <td>18484</td>\n",
       "      <td>25557</td>\n",
       "      <td>18484</td>\n",
       "      <td>12429</td>\n",
       "      <td>8541</td>\n",
       "      <td>25557</td>\n",
       "      <td>14122</td>\n",
       "      <td>23610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14122</td>\n",
       "      <td>39490</td>\n",
       "      <td>27271</td>\n",
       "      <td>39764</td>\n",
       "      <td>28167</td>\n",
       "      <td>8875</td>\n",
       "      <td>1494</td>\n",
       "      <td>40182</td>\n",
       "      <td>6951</td>\n",
       "      <td>39745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>219</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34155</td>\n",
       "      <td>14517</td>\n",
       "      <td>19363</td>\n",
       "      <td>40032</td>\n",
       "      <td>14122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>271</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10818</td>\n",
       "      <td>2776</td>\n",
       "      <td>9421</td>\n",
       "      <td>19118</td>\n",
       "      <td>3218</td>\n",
       "      <td>14122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   helpful  encoded_1  encoded_2  encoded_3  encoded_4  encoded_5  encoded_6  \\\n",
       "0        4          0          0          0          0          0          0   \n",
       "1        0          0          0          0          0          0          0   \n",
       "2        0          0          0          0          0          0          0   \n",
       "7      219          0          0          0          0          0          0   \n",
       "9      271          0          0          0          0          0          0   \n",
       "\n",
       "   encoded_7  encoded_8  encoded_9  ...  encoded_185  encoded_186  \\\n",
       "0          0          0          0  ...        33572        15335   \n",
       "1          0          0          0  ...            0            0   \n",
       "2          0          0          0  ...        14122        39490   \n",
       "7          0          0          0  ...            0            0   \n",
       "9          0          0          0  ...            0            0   \n",
       "\n",
       "   encoded_187  encoded_188  encoded_189  encoded_190  encoded_191  \\\n",
       "0        18484        25557        18484        12429         8541   \n",
       "1            0            0            0            0            0   \n",
       "2        27271        39764        28167         8875         1494   \n",
       "7            0            0            0        34155        14517   \n",
       "9            0            0        10818         2776         9421   \n",
       "\n",
       "   encoded_192  encoded_193  encoded_194  \n",
       "0        25557        14122        23610  \n",
       "1            0            0        30552  \n",
       "2        40182         6951        39745  \n",
       "7        19363        40032        14122  \n",
       "9        19118         3218        14122  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_columns = [x for x in df.columns.tolist() if x.startswith('title_')]\n",
    "drop_cols = ['funny', 'is_early_access_review', 'recommendation', 'review', 'cleaned_reviews', 'hour_played', 'Year', 'Month', 'Day']\n",
    "drop_cols += title_columns\n",
    "\n",
    "df.drop(drop_cols, axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoded_1</th>\n",
       "      <th>encoded_2</th>\n",
       "      <th>encoded_3</th>\n",
       "      <th>encoded_4</th>\n",
       "      <th>encoded_5</th>\n",
       "      <th>encoded_6</th>\n",
       "      <th>encoded_7</th>\n",
       "      <th>encoded_8</th>\n",
       "      <th>encoded_9</th>\n",
       "      <th>encoded_10</th>\n",
       "      <th>...</th>\n",
       "      <th>encoded_186</th>\n",
       "      <th>encoded_187</th>\n",
       "      <th>encoded_188</th>\n",
       "      <th>encoded_189</th>\n",
       "      <th>encoded_190</th>\n",
       "      <th>encoded_191</th>\n",
       "      <th>encoded_192</th>\n",
       "      <th>encoded_193</th>\n",
       "      <th>encoded_194</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15335</td>\n",
       "      <td>18484</td>\n",
       "      <td>25557</td>\n",
       "      <td>18484</td>\n",
       "      <td>12429</td>\n",
       "      <td>8541</td>\n",
       "      <td>25557</td>\n",
       "      <td>14122</td>\n",
       "      <td>23610</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39490</td>\n",
       "      <td>27271</td>\n",
       "      <td>39764</td>\n",
       "      <td>28167</td>\n",
       "      <td>8875</td>\n",
       "      <td>1494</td>\n",
       "      <td>40182</td>\n",
       "      <td>6951</td>\n",
       "      <td>39745</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34155</td>\n",
       "      <td>14517</td>\n",
       "      <td>19363</td>\n",
       "      <td>40032</td>\n",
       "      <td>14122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10818</td>\n",
       "      <td>2776</td>\n",
       "      <td>9421</td>\n",
       "      <td>19118</td>\n",
       "      <td>3218</td>\n",
       "      <td>14122</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encoded_1  encoded_2  encoded_3  encoded_4  encoded_5  encoded_6  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          0          0          0          0          0   \n",
       "2          0          0          0          0          0          0   \n",
       "7          0          0          0          0          0          0   \n",
       "9          0          0          0          0          0          0   \n",
       "\n",
       "   encoded_7  encoded_8  encoded_9  encoded_10  ...  encoded_186  encoded_187  \\\n",
       "0          0          0          0           0  ...        15335        18484   \n",
       "1          0          0          0           0  ...            0            0   \n",
       "2          0          0          0           0  ...        39490        27271   \n",
       "7          0          0          0           0  ...            0            0   \n",
       "9          0          0          0           0  ...            0            0   \n",
       "\n",
       "   encoded_188  encoded_189  encoded_190  encoded_191  encoded_192  \\\n",
       "0        25557        18484        12429         8541        25557   \n",
       "1            0            0            0            0            0   \n",
       "2        39764        28167         8875         1494        40182   \n",
       "7            0            0        34155        14517        19363   \n",
       "9            0        10818         2776         9421        19118   \n",
       "\n",
       "   encoded_193  encoded_194  helpful  \n",
       "0        14122        23610        1  \n",
       "1            0        30552        0  \n",
       "2         6951        39745        0  \n",
       "7        40032        14122        1  \n",
       "9         3218        14122        1  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to classification problem --> turn helpful to 0s 1s\n",
    "new_helpful = []\n",
    "num_positive = 0\n",
    "for val in df.helpful.tolist():\n",
    "    if val > 0:\n",
    "        new_helpful.append(1)\n",
    "        num_positive += 1\n",
    "    else:\n",
    "        new_helpful.append(0)\n",
    "df.drop(['helpful'], axis=1, inplace=True)\n",
    "df['helpful'] = new_helpful\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = len(df.columns.tolist())-1\n",
    "VOCAB_SIZE = 41248 # should ideally just transport this from prev\n",
    "EMBED_DIM = 128\n",
    "LSTM_DIM = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking = True\n",
    "\n",
    "        self.bias = bias\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        \n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.kaiming_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        \n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        feature_dim = self.feature_dim \n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim), \n",
    "            self.weight\n",
    "        ).view(-1, step_dim)\n",
    "        \n",
    "        if self.bias:\n",
    "            eij = eij + self.b\n",
    "            \n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        \n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "\n",
    "        a = a / (torch.sum(a, 1, keepdim=True) + 1e-10)\n",
    "\n",
    "        weighted_input = x * torch.unsqueeze(a, -1)\n",
    "        return torch.sum(weighted_input, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pytorch model\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "class Attention_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention_Net, self).__init__()\n",
    "        \n",
    "        # define architecture\n",
    "        self.embedding = nn.Embedding(VOCAB_SIZE, EMBED_DIM)\n",
    "#         self.embedding_dropout = nn.Dropout2d(DROPOUT) # take this out potentially\n",
    "        \n",
    "        self.lstm = nn.LSTM(EMBED_DIM, LSTM_DIM, bidirectional=True, batch_first=True)\n",
    "        \n",
    "        # attention layer\n",
    "        self.attention_layer = Attention(LSTM_DIM * 2, MAX_SEQ_LEN)\n",
    "        \n",
    "        self.linear = nn.Linear(LSTM_DIM * 2, 2)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0)).view(BATCH_SIZE, MAX_SEQ_LEN, -1)\n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        h_lstm_atten = self.attention_layer(h_lstm)\n",
    "        out = self.linear(h_lstm_atten)\n",
    "        softmax_out = self.softmax(out)\n",
    "        return softmax_out\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SteamDataset(data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        #'Initialization'\n",
    "        self.data = data\n",
    "        text_cols = [x for x in df.columns.tolist() if x.startswith(\"encoded\")]\n",
    "        self.train = torch.tensor(data[text_cols].values).cuda()\n",
    "        labels = data['helpful'].tolist()\n",
    "        \n",
    "        one_hot_labels = []\n",
    "        for val in labels:\n",
    "            if val == 0:\n",
    "                one_hot_labels.append([1, 0])\n",
    "#                 one_hot_labels.append([0])\n",
    "            else:\n",
    "                one_hot_labels.append([0, 1])\n",
    "#                 one_hot_labels.append([1])\n",
    "        self.one_hot_labels = torch.tensor(np.array(one_hot_labels)).squeeze().type(torch.FloatTensor).cuda() # change to longtensor if using custom loss\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        #'Denotes the total number of samples'\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #'Generates one sample of data'\n",
    "        \n",
    "        # Load data and get label\n",
    "        X = self.train[index]\n",
    "        Y = self.one_hot_labels[index]\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = int(0.8 * len(df))\n",
    "steam_dataset = SteamDataset(df[:train_num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1b8048cc9c8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steam_data_loader = data.DataLoader(steam_dataset, batch_size=16, num_workers=0, drop_last=True)\n",
    "steam_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive examples =  32126\n",
      "negative examples =  373543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0860, 12.6274], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_negative = len(df) - num_positive\n",
    "print ('positive examples = ', num_positive)\n",
    "print ('negative examples = ', num_negative)\n",
    "\n",
    "weights = torch.tensor([1/(num_negative / len(df)), 1 / (num_positive / len(df))]).cuda()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_model = Attention_Net().cuda()\n",
    "# loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(attention_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_binary_cross_entropy(output, target, weights=None):\n",
    "        \n",
    "    if weights is not None:\n",
    "        assert len(weights) == 2\n",
    "        \n",
    "        loss = weights[1] * (target * torch.log(output)) + \\\n",
    "               weights[0] * ((1 - target) * torch.log(1 - output))\n",
    "    else:\n",
    "        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
    "\n",
    "    return torch.neg(torch.mean(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 10000 train batches | took 153.12880277633667 seconds | loss: 0.10620594024658203\n",
      "For 10000 train batches | took 156.99644255638123 seconds | loss: 0.08813270181417465\n",
      "On epoch: 2\n",
      "For 10000 train batches | took 170.56140208244324 seconds | loss: 0.10770267248153687\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "EPOCHS = 5\n",
    "checkpoint_num = 10000\n",
    "start = time.time()\n",
    "\n",
    "running_loss = 0\n",
    "for i in range(EPOCHS):\n",
    "    print (\"On epoch: {}\".format(i+1))\n",
    "    idx = 0\n",
    "    second_start = time.time()\n",
    "    for train_X, train_Y in steam_data_loader:\n",
    "        if (idx+1) % checkpoint_num == 0:\n",
    "            print ('For {} train batches | took {} seconds | loss: {}'\n",
    "                   .format(checkpoint_num, time.time() - second_start, running_loss / (checkpoint_num*BATCH_SIZE)))\n",
    "            second_start = time.time()\n",
    "            running_loss = 0\n",
    "            \n",
    "        attention_model.zero_grad()\n",
    "        pred_y = attention_model(train_X)       \n",
    "\n",
    "        loss = weighted_binary_cross_entropy(pred_y, train_Y, weights)\n",
    "        # print ('pred_y = ', pred_y)\n",
    "        # print ('train_Y = ', train_Y)\n",
    "        # loss = loss_function(pred_y, train_Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        idx+=1\n",
    "        \n",
    "print (\"Took {} seconds\".format(time.time() - start))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted helpful =  tensor([[0.6429]])\n",
      "actual helpful =  tensor([4.])\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "with torch.no_grad():\n",
    "    \n",
    "    preds = attention_model(train_X[0])\n",
    "    print ('predicted helpful = ', preds)\n",
    "    print ('actual helpful = ', train_Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce GTX 1060 with Max-Q Design'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631242752"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the current GPU memory usage by \n",
    "# tensors in bytes for a given device\n",
    "torch.cuda.memory_allocated()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "631242752"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns the current GPU memory managed by the\n",
    "# caching allocator in bytes for a given device\n",
    "torch.cuda.memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(attention_model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
