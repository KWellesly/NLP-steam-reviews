{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import sys\n",
    "\n",
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "GeForce GTX 1060 with Max-Q Design\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print (torch.cuda.is_available())\n",
    "print (torch.cuda.current_device())\n",
    "print (torch.cuda.get_device_name(0))\n",
    "print (torch.cuda.memory_allocated())\n",
    "print (torch.cuda.memory_cached())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleaned_amzn_data_4-15_10Kwords.csv\", encoding='utf8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendation</th>\n",
       "      <th>encoded_1</th>\n",
       "      <th>encoded_2</th>\n",
       "      <th>encoded_3</th>\n",
       "      <th>encoded_4</th>\n",
       "      <th>encoded_5</th>\n",
       "      <th>encoded_6</th>\n",
       "      <th>encoded_7</th>\n",
       "      <th>encoded_8</th>\n",
       "      <th>encoded_9</th>\n",
       "      <th>...</th>\n",
       "      <th>encoded_185</th>\n",
       "      <th>encoded_186</th>\n",
       "      <th>encoded_187</th>\n",
       "      <th>encoded_188</th>\n",
       "      <th>encoded_189</th>\n",
       "      <th>encoded_190</th>\n",
       "      <th>encoded_191</th>\n",
       "      <th>encoded_192</th>\n",
       "      <th>encoded_193</th>\n",
       "      <th>encoded_194</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4059</td>\n",
       "      <td>9289</td>\n",
       "      <td>8594</td>\n",
       "      <td>9289</td>\n",
       "      <td>4934</td>\n",
       "      <td>7474</td>\n",
       "      <td>3382</td>\n",
       "      <td>652</td>\n",
       "      <td>2097</td>\n",
       "      <td>2876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3340</td>\n",
       "      <td>8561</td>\n",
       "      <td>9289</td>\n",
       "      <td>214</td>\n",
       "      <td>5126</td>\n",
       "      <td>6257</td>\n",
       "      <td>2827</td>\n",
       "      <td>6823</td>\n",
       "      <td>1256</td>\n",
       "      <td>8798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1745</td>\n",
       "      <td>5242</td>\n",
       "      <td>506</td>\n",
       "      <td>2434</td>\n",
       "      <td>7599</td>\n",
       "      <td>8764</td>\n",
       "      <td>5242</td>\n",
       "      <td>7146</td>\n",
       "      <td>6949</td>\n",
       "      <td>3506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7514</td>\n",
       "      <td>5853</td>\n",
       "      <td>5815</td>\n",
       "      <td>9606</td>\n",
       "      <td>595</td>\n",
       "      <td>8561</td>\n",
       "      <td>243</td>\n",
       "      <td>2076</td>\n",
       "      <td>2734</td>\n",
       "      <td>9289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8375</td>\n",
       "      <td>3595</td>\n",
       "      <td>1356</td>\n",
       "      <td>2298</td>\n",
       "      <td>8561</td>\n",
       "      <td>7502</td>\n",
       "      <td>2298</td>\n",
       "      <td>1329</td>\n",
       "      <td>6555</td>\n",
       "      <td>6758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 195 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   recommendation  encoded_1  encoded_2  encoded_3  encoded_4  encoded_5  \\\n",
       "0               0          0          0          0          0          0   \n",
       "1               1          0          0          0          0          0   \n",
       "2               0          0          0          0          0          0   \n",
       "4               1          0          0          0          0          0   \n",
       "5               1          0          0          0          0          0   \n",
       "\n",
       "   encoded_6  encoded_7  encoded_8  encoded_9  ...  encoded_185  encoded_186  \\\n",
       "0          0          0          0          0  ...         4059         9289   \n",
       "1          0          0          0          0  ...         3340         8561   \n",
       "2          0          0          0          0  ...         1745         5242   \n",
       "4          0          0          0          0  ...         7514         5853   \n",
       "5          0          0          0          0  ...         8375         3595   \n",
       "\n",
       "   encoded_187  encoded_188  encoded_189  encoded_190  encoded_191  \\\n",
       "0         8594         9289         4934         7474         3382   \n",
       "1         9289          214         5126         6257         2827   \n",
       "2          506         2434         7599         8764         5242   \n",
       "4         5815         9606          595         8561          243   \n",
       "5         1356         2298         8561         7502         2298   \n",
       "\n",
       "   encoded_192  encoded_193  encoded_194  \n",
       "0          652         2097         2876  \n",
       "1         6823         1256         8798  \n",
       "2         7146         6949         3506  \n",
       "4         2076         2734         9289  \n",
       "5         1329         6555         6758  \n",
       "\n",
       "[5 rows x 195 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols = ['review', 'cleaned_reviews']\n",
    "\n",
    "try:\n",
    "    df.drop(drop_cols, axis=1, inplace=True)\n",
    "except:\n",
    "    print (\"Probably dropped already\")\n",
    "df = df.rename(columns={'overall': 'recommendation'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = len(df.columns.tolist())-1\n",
    "VOCAB_SIZE = 10746 # should ideally just transport this from prev\n",
    "EMBED_DIM = 32\n",
    "LSTM_DIM = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pytorch model\n",
    "DROPOUT = 0.1\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "class Attention_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention_Net, self).__init__()\n",
    "        \n",
    "        # Number of input features is 12.\n",
    "        self.layer_1 = nn.Linear(MAX_SEQ_LEN, 64) \n",
    "        self.layer_2 = nn.Linear(64, 64)\n",
    "        self.layer_out = nn.Linear(64, 1) \n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        x = self.relu(self.layer_1(inputs))\n",
    "        x = self.batchnorm1(x)\n",
    "        x = self.relu(self.layer_2(x))\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.layer_out(x)\n",
    "        return self.sig(x)\n",
    "#         # define architecture\n",
    "# #         self.embedding = nn.Embedding(VOCAB_SIZE, EMBED_DIM)\n",
    "        \n",
    "# #         self.lstm = nn.LSTM(EMBED_DIM, \n",
    "# #                             LSTM_DIM, \n",
    "# #                             bidirectional=True,\n",
    "# #                             dropout=0.2,\n",
    "# #                             batch_first=True)\n",
    "#         self.first_lin = nn.Linear(MAX_SEQ_LEN, 64)\n",
    "#         self.leakyrelu = nn.LeakyReLU()\n",
    "#         self.linear = nn.Linear(64, 1)\n",
    "# #         self.linear = nn.Linear(LSTM_DIM * 2, 1)\n",
    "#         self.activation = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out = self.first_lin(x)\n",
    "#         out = self.leakyrelu(out)\n",
    "#         out = self.linear(out)\n",
    "#         out = self.activation(out)\n",
    "#         return out\n",
    "# #         h_embedding = self.embedding(x)\n",
    "# #         h_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0)).view(BATCH_SIZE, MAX_SEQ_LEN, -1)\n",
    "# #         lstm_out, _ = self.lstm(h_embedding)\n",
    "        \n",
    "# #         relu = self.leakyrelu(lstm_out[:, -1, :])\n",
    "# #         out = self.linear(relu)\n",
    "# #         activated_out = self.activation(out)\n",
    "# #         return activated_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AmznDataset(data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        #'Initialization'\n",
    "        self.data = data\n",
    "        text_cols = [x for x in df.columns.tolist() if x.startswith(\"encoded\")]\n",
    "        self.train = torch.tensor(data[text_cols].values).type(torch.FloatTensor).cuda()\n",
    "        labels = data['recommendation'].tolist()\n",
    "        \n",
    "        self.one_hot_labels = torch.tensor(np.array(labels)).squeeze().type(torch.FloatTensor).cuda() # change to longtensor if using custom loss\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        #'Denotes the total number of samples'\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #'Generates one sample of data'\n",
    "        \n",
    "        # Load data and get label\n",
    "        X = self.train[index]\n",
    "        Y = self.one_hot_labels[index]\n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x23996fbca48>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_num = int(0.8 * len(df))\n",
    "amzn_dataset = AmznDataset(df[:train_num])\n",
    "amzn_data_loader = data.DataLoader(amzn_dataset, batch_size=BATCH_SIZE, num_workers=0, drop_last=True, shuffle=True)\n",
    "amzn_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_model = Attention_Net().cuda()\n",
    "# loss_function = nn.CrossEntropyLoss(weight=weights)\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "loss_function = nn.BCELoss().cuda()\n",
    "optimizer = optim.SGD(attention_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12dcd97b802c4b21b52d73151785956c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 | took 18.701964855194092 seconds | summed loss: 1348.1436767578125 | avg loss: 0.008697252720594406\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce0945f419c4b97b317d1587d873579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 | took 18.79474139213562 seconds | summed loss: 1328.5531005859375 | avg loss: 0.008570868521928787\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396c37f3766c46b1a21e22ae408461e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 | took 18.585352897644043 seconds | summed loss: 1327.464111328125 | avg loss: 0.008563842624425888\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740cf55b4ce94f0da3414bddedfc0dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 | took 18.67605948448181 seconds | summed loss: 1327.1907958984375 | avg loss: 0.008562079630792141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b569cb1adca4eb692920cc69562c950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2422.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 | took 18.85761046409607 seconds | summed loss: 1326.9930419921875 | avg loss: 0.008560803718864918\n",
      "Took 93.62165307998657 seconds\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "EPOCHS = 5\n",
    "start = time.time()\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    second_start = time.time()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    \n",
    "    with tqdm(total=len(amzn_data_loader), file=sys.stdout) as pbar:\n",
    "        for idx, (train_X, train_Y) in enumerate(amzn_data_loader):\n",
    "            attention_model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            \n",
    "            pred_y = attention_model(train_X)  \n",
    "#             print ('pred_y = ', pred_y)\n",
    "            loss = loss_function(pred_y, train_Y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss\n",
    "\n",
    "            pbar.set_description('ep{} | loss: {}'.format(i+1, torch.round(running_loss)))\n",
    "\n",
    "\n",
    "            pbar.update(1)\n",
    "            tqdm._instances.clear()\n",
    "            \n",
    "            \n",
    "    \n",
    "    \n",
    "\n",
    "    print ('Epoch {} | took {} seconds | summed loss: {} | avg loss: {}'\n",
    "                   .format(i+1, time.time() - second_start, running_loss, running_loss / (len(amzn_data_loader) * BATCH_SIZE)))\n",
    "\n",
    "print (\"Took {} seconds\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_eval_dataset = AmznDataset(df[train_num:])\n",
    "amzn_eval_data_loader = data.DataLoader(amzn_eval_dataset, batch_size=BATCH_SIZE, num_workers=0, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval accuracy: 0.7792687017779268\n",
      "Eval summed loss: 315.85833740234375 | avg loss: 0.008150552399456501\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "correct = 0\n",
    "eval_loss = 0\n",
    "with torch.no_grad():\n",
    "    for i, (test_X, test_Y) in enumerate(amzn_eval_data_loader):\n",
    "        preds = attention_model(test_X)\n",
    "#         print (\"preds = \", preds)\n",
    "#         print (\"test_Y = \", test_Y)\n",
    "        for idx, each_pred in enumerate(preds):\n",
    "            if each_pred[0] >= 0.5 and test_Y[idx] == 1:\n",
    "                correct += 1\n",
    "            elif each_pred[0] < 0.5 and test_Y[idx] == 0:\n",
    "                correct += 1\n",
    "        loss = loss_function(preds, test_Y)\n",
    "        eval_loss += loss\n",
    "        \n",
    "        \n",
    "print (\"Eval accuracy: {}\".format(correct / len(amzn_eval_dataset)))\n",
    "print (\"Eval summed loss: {} | avg loss: {}\".format(eval_loss, eval_loss / len(amzn_eval_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'models/amzn_date4-15_batch32_epoch5.pt'\n",
    "torch.save(attention_model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7620507421399227"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(df.recommendation.tolist()) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 77.8% eval acc -- batch=128, lr=0.0001\n",
    "# 77.8% eval acc -- batch=128, lr=0.001\n",
    "# 77.9% eval acc -- batch=64, lr=0.001, embed_dim=16, lstm_dim=16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
